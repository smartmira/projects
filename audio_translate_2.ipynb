{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "608fc995-aa66-4a8b-8613-c7e304b719d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5df56c18-3422-429a-8e6f-672cc7267cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "import tempfile\n",
    "import whisper\n",
    "from pydub import AudioSegment\n",
    "from openai import OpenAI\n",
    "from TTS.api import TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "199e8d9c-2ffe-49d5-a15f-d77a123c2941",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffa4187c-cfa7-458d-af06-eb2cc5834163",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_model = whisper.load_model(\"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "474afaa9-65f7-40a2-bae0-6dd40eb17fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\miniconda3\\envs\\audio_translate\\lib\\site-packages\\TTS\\tts\\layers\\xtts\\xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.speakers = torch.load(speaker_file_path)\n",
      "C:\\Users\\USER\\miniconda3\\envs\\audio_translate\\lib\\site-packages\\TTS\\utils\\io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "tts_model = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06f00c1f-e2f0-4927-bdb5-ee808da19b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\miniconda3\\envs\\audio_translate\\lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['Lib, −�� Douglas, − et rabroue sax sur le côté Corin mets tag gawon triomphe.']\n",
      " > Processing time: 59.74814987182617\n",
      " > Real-time factor: 5.801480944276083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\USER\\miniconda3\\envs\\audio_translate\\lib\\site-packages\\gradio\\queueing.py\", line 759, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\USER\\miniconda3\\envs\\audio_translate\\lib\\site-packages\\gradio\\route_utils.py\", line 354, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\USER\\miniconda3\\envs\\audio_translate\\lib\\site-packages\\gradio\\blocks.py\", line 2116, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\USER\\miniconda3\\envs\\audio_translate\\lib\\site-packages\\gradio\\blocks.py\", line 1623, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"C:\\Users\\USER\\miniconda3\\envs\\audio_translate\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"C:\\Users\\USER\\miniconda3\\envs\\audio_translate\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2485, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\USER\\miniconda3\\envs\\audio_translate\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 976, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\USER\\miniconda3\\envs\\audio_translate\\lib\\site-packages\\gradio\\utils.py\", line 915, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_12796\\1620095288.py\", line 27, in translate_from_english\n",
      "    AudioSegment.from_file(audio).export(tmp.name, format=\"wav\")\n",
      "  File \"C:\\Users\\USER\\miniconda3\\envs\\audio_translate\\lib\\site-packages\\pydub\\audio_segment.py\", line 723, in from_file\n",
      "    stdin_data = file.read()\n",
      "AttributeError: 'NoneType' object has no attribute 'read'\n",
      "C:\\Users\\USER\\miniconda3\\envs\\audio_translate\\lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['Bonjour, je veux juste savoir si tu vas bien.']\n",
      " > Processing time: 46.48140907287598\n",
      " > Real-time factor: 6.627748771707936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\miniconda3\\envs\\audio_translate\\lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['Bonjour, je veux juste savoir comment tu vas.']\n",
      " > Processing time: 32.19431161880493\n",
      " > Real-time factor: 6.014339934887563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\miniconda3\\envs\\audio_translate\\lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_12796\\1620095288.py:84: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(english_audio_out)\n",
      "C:\\Users\\USER\\miniconda3\\envs\\audio_translate\\lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "LANGUAGES = [\"French\", \"German\", \"Spanish\", \"Hindi\", \"Russian\", \"Chinese\"]\n",
    "\n",
    "LANGUAGE_CODES = {\n",
    "    \"french\": \"fr\",\n",
    "    \"german\": \"de\",\n",
    "    \"spanish\": \"es\",\n",
    "    \"hindi\": \"hi\",\n",
    "    \"russian\": \"ru\",\n",
    "    \"chinese\": \"zh-cn\"\n",
    "}\n",
    "\n",
    "os.makedirs(\"user_voices\", exist_ok=True)\n",
    "DEFAULT_VOICE_PATH = \"user_voices/my_voice.wav\"\n",
    "\n",
    "\n",
    "def save_voice_sample(audio):\n",
    "    if audio is None:\n",
    "        return \"⚠️ Please record a voice first.\", None\n",
    "\n",
    "\n",
    "    output_path = DEFAULT_VOICE_PATH\n",
    "    AudioSegment.from_file(audio).export(output_path, format=\"wav\")\n",
    "    return f\"✅ Voice sample saved as {output_path}.\", output_path\n",
    "\n",
    "def translate_from_english(audio, target_lang):\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp:\n",
    "        AudioSegment.from_file(audio).export(tmp.name, format=\"wav\")\n",
    "        audio_path = tmp.name\n",
    "\n",
    "    result = whisper_model.transcribe(audio_path)\n",
    "    english_text = result[\"text\"]\n",
    "\n",
    "    translation = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"Translate this from English to {target_lang}.\"},\n",
    "            {\"role\": \"user\", \"content\": english_text}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    translated_text = translation.choices[0].message.content\n",
    "    lang_code = LANGUAGE_CODES.get(target_lang.lower(), target_lang.lower())\n",
    "\n",
    "    speaker_wav = DEFAULT_VOICE_PATH if os.path.exists(DEFAULT_VOICE_PATH) else None\n",
    "\n",
    "    audio_out_path = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False).name\n",
    "    tts_model.tts_to_file(\n",
    "        text=translated_text,\n",
    "        speaker_wav=speaker_wav,\n",
    "        language=lang_code,\n",
    "        file_path=audio_out_path\n",
    "    )\n",
    "\n",
    "    return translated_text, audio_out_path\n",
    "\n",
    "\n",
    "def translate_to_english(audio, source_lang):\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp:\n",
    "        AudioSegment.from_file(audio).export(tmp.name, format=\"wav\")\n",
    "        audio_path = tmp.name\n",
    "\n",
    "    result = whisper_model.transcribe(audio_path)\n",
    "    source_text = result[\"text\"]\n",
    "\n",
    "    translation = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"Translate this from {source_lang} to English.\"},\n",
    "            {\"role\": \"user\", \"content\": source_text}\n",
    "             \n",
    "        ]\n",
    "    )\n",
    "    translated_text = translation.choices[0].message.content\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as tmp_audio:\n",
    "        english_audio_out = tmp_audio.name\n",
    "\n",
    "    response = client.audio.speech.create(\n",
    "        model=\"gpt-4o-mini-tts\",\n",
    "        voice=\"alloy\",\n",
    "        input=translated_text\n",
    "    )\n",
    "\n",
    "    response.stream_to_file(english_audio_out)\n",
    "\n",
    "    return translated_text, english_audio_out\n",
    "\n",
    "def text_translate(text, target_lang, direction):\n",
    "    \"\"\"Translate text in either direction (English <-> Target).\"\"\"\n",
    "    \n",
    "    if direction == \"English → Target\":\n",
    "        src_lang = \"English\"\n",
    "        tgt_lang = target_lang\n",
    "    else:\n",
    "        src_lang = target_lang\n",
    "        tgt_lang = \"English\"\n",
    "\n",
    "    translation = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    f\"You are a professional translator. Translate ONLY the following text \"\n",
    "                    f\"from {src_lang} to {tgt_lang}. \"\n",
    "                    f\"Respond with ONLY the translated text — no explanations, no quotes, no extra words.\"\n",
    "                )\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return translation.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "with gr.Blocks(title=\"🌍 AI Voice Translator Studio\") as demo:\n",
    "    gr.Markdown(\"## 🎙️ Your AI Voice Translator — Speak, Record, and Communicate Effortlessly\")\n",
    "    \n",
    "    with gr.Tab(\"🧠 1. Record & Save Your Voice\"):\n",
    "        gr.Markdown(\"Record your voice — the app will use it for translations from English.\")\n",
    "        voice_input = gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"🎤 Record your voice sample\")\n",
    "        save_button = gr.Button(\"💾 Save Voice Sample\")\n",
    "        voice_status = gr.Textbox(label=\"Status\", interactive=False)\n",
    "        saved_voice_preview = gr.Audio(label=\"🔊 Your Saved Voice\")\n",
    "        save_button.click(save_voice_sample, inputs=voice_input, outputs=[voice_status, saved_voice_preview])\n",
    "\n",
    "    with gr.Tab(\"🌍 2. English → Target Language (Your Voice)\"):\n",
    "        gr.Interface(\n",
    "            fn=translate_from_english,\n",
    "            inputs=[\n",
    "                gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"🎙️ Speak English\"),\n",
    "                gr.Dropdown(LANGUAGES, label=\"Translate to\", value=\"French\")\n",
    "            ],\n",
    "            outputs=[\n",
    "                gr.Textbox(label=\"📝 Translated Text\"),\n",
    "                gr.Audio(label=\"🔊 Translation (Your Voice)\", interactive=True, show_download_button=True)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    with gr.Tab(\"🗣️ 3. Target Language → English (AI Voice)\"):\n",
    "        gr.Interface(\n",
    "            fn=translate_to_english,\n",
    "            inputs=[\n",
    "                gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"🎙️ Speak in Target Language\"),\n",
    "                gr.Dropdown(LANGUAGES, label=\"Source Language\", value=\"French\")\n",
    "            ],\n",
    "            outputs=[\n",
    "                gr.Textbox(label=\"📝 English Translation\"),\n",
    "                gr.Audio(label=\"🔊 English Voice (GPT Voice)\", interactive=True, show_download_button=True)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    with gr.Tab(\"💬 4. Text Translator\"):\n",
    "        gr.Interface(\n",
    "            fn=text_translate,\n",
    "            inputs=[\n",
    "                gr.Textbox(label=\"✍️ Enter text to translate\"),\n",
    "                gr.Dropdown(LANGUAGES, label=\"🌍 Choose Language\", value=\"Spanish\"),\n",
    "                gr.Radio([\"English → Target\", \"Target → English\"], label=\"Translation Direction\", value=\"English → Target\")\n",
    "            ],\n",
    "            outputs=gr.Textbox(label=\"📝 Translated Text\")\n",
    "        )\n",
    "\n",
    "demo.launch()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f4992de-fac9-480a-a492-5e79ce16ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall -y numpy==2.2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6974e1d-1909-43bb-b55e-f17d5ac215b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -c \"import numpy; print(numpy.__version__)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d54ec-6cf8-459c-a2b2-a6cadcbde22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f31ba44-f8bd-4440-a755-57b5c7e602ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy==1.22.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04489e34-4fb6-4206-8633-5ea9ba0a45e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -c \"import numpy; print(numpy.__version__)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b12be09b-70ab-4126-b831-3253b0282e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers==4.37.2 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58c908c6-83a5-437f-854c-b2391b983864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sounddevice scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa93da1-f428-420d-8a3e-89abebcd9cc5",
   "metadata": {},
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "fs = 44100\n",
    "seconds = 10\n",
    "\n",
    "print(\"Recording... Speak now!\")\n",
    "\n",
    "recording = sd.rec(int(seconds * fs), samplerate=fs, channels=1, dtype='int16')\n",
    "\n",
    "sd.wait()\n",
    "\n",
    "print(\"Recording complete!\")\n",
    "\n",
    "write(\"my_voice1.wav\", fs, recording)\n",
    "print(\"saved as my_voice1.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed00616-51c0-451c-9e2c-e316e45e4da1",
   "metadata": {},
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "# use the filename parameter explicitly\n",
    "Audio(filename=\"my_voice1.wav\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f015bf3-fda4-4a7f-a525-f9112e959cf6",
   "metadata": {},
   "source": [
    "LANGUAGES = [\"French\", \"German\", \"Spanish\", \"Hindi\", \"Russian\", \"Chinese\"]\n",
    "\n",
    "# Map display names → valid TTS language codes\n",
    "LANGUAGE_CODES = {\n",
    "    \"french\": \"fr\",\n",
    "    \"german\": \"de\",\n",
    "    \"spanish\": \"es\",\n",
    "    \"hindi\": \"hi\",\n",
    "    \"russian\": \"ru\",\n",
    "    \"chinese\": \"zh-cn\"   # ✅ corrected\n",
    "}\n",
    "\n",
    "MY_VOICE_SAMPLE = \"my_voice1.wav\"\n",
    "\n",
    "def translate_voice_note(audio, target_lang):\n",
    "    import tempfile\n",
    "    from pydub import AudioSegment\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp:\n",
    "        AudioSegment.from_file(audio).export(tmp.name, format=\"wav\")\n",
    "        audio_path = tmp.name\n",
    "\n",
    "    result = whisper_model.transcribe(audio_path)\n",
    "    english_text = result[\"text\"]\n",
    "\n",
    "    # Translate text using GPT\n",
    "    translation = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"Translate this from English to {target_lang}.\"},\n",
    "            {\"role\": \"user\", \"content\": english_text}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    translated_text = translation.choices[0].message.content\n",
    "\n",
    "    # ✅ Correct the language code for TTS\n",
    "    lang_code = LANGUAGE_CODES.get(target_lang.lower(), target_lang.lower())\n",
    "\n",
    "    audio_out_path = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False).name\n",
    "    tts_model.tts_to_file(\n",
    "        text=translated_text,\n",
    "        speaker_wav=MY_VOICE_SAMPLE,\n",
    "        language=lang_code,\n",
    "        file_path=audio_out_path  # ✅ was previously \"audio\" by mistake\n",
    "    )\n",
    "\n",
    "    return translated_text, audio_out_path\n",
    "\n",
    "\n",
    "# Gradio interface\n",
    "demo = gr.Interface(\n",
    "    fn=translate_voice_note,\n",
    "    inputs=[\n",
    "        gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"🎙️ Record your English voice note\"),\n",
    "        gr.Dropdown(LANGUAGES, label=\"🌍 Choose target language\", value=\"Chinese\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"📝 Translated Text\"),\n",
    "        gr.Audio(label=\"🔊 Translated Voice (Your Voice!)\")\n",
    "    ],\n",
    "    title=\"🌍 Personal Voice Translator\",\n",
    "    description=\"Record an English voice note — it translates into your chosen language and speaks back in your own voice.\"\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cc0dae-e83b-491a-9383-c4a15e9767a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
